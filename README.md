---

# ğŸ“˜ **AI Conversation Analysis System**

This project is a **Django + DRF-based AI Conversation Analysis System** developed as part of a **technical assessment**.
It allows uploading chat conversations, analyzing them using custom logic, and generating daily automated analysis reports using **Celery Beat**.

The system evaluates conversations across multiple quality metrics such as **clarity**, **relevance**, **accuracy**, **sentiment**, **empathy**, **fallback**, **resolution**, and more.


---

# ğŸš€ **Features**

### ğŸ“ Upload Conversations

Send chat messages (user + AI) to the system.

### ğŸ¤– Automated Conversation Analysis

Generates multiple metrics:

* Clarity
* Relevance
* Accuracy
* Completeness
* Sentiment
* Empathy
* Fallback Count
* Resolution
* Response Time
* Overall Score

### ğŸ“Š View All Analysis Reports

REST endpoint for all stored analysis records.

### â± Daily Scheduled Auto-Analysis

Celery Beat automatically processes un-analysed conversations.

### ğŸ“˜ Live API Documentation

Swagger UI for easy API testing.

---

# ğŸ›  **Tech Stack**

| Component  | Technology             |
| ---------- | ---------------------- |
| Backend    | Django 5, DRF          |
| NLP        | TextBlob, NLTK WordNet |
| Task Queue | Celery                 |
| Scheduler  | Celery Beat            |
| Broker     | Redis                  |
| Database   | SQLite                 |
| API Docs   | Swagger (drf-yasg)     |
| Python     | 3.8+                   |

---

# ğŸ“‚ **Project Structure**

```
kipps_analysis/
â”‚
â”œâ”€â”€ kipps_analysis/
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ celery.py
â”‚   â”œâ”€â”€ urls.py
â”‚   â””â”€â”€ wsgi.py
â”‚
â”œâ”€â”€ conversations/
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ serializers.py
â”‚   â”œâ”€â”€ views.py
â”‚   â”œâ”€â”€ analysis_logic.py
â”‚   â”œâ”€â”€ tasks.py
â”‚   â”œâ”€â”€ urls.py
â”‚   â””â”€â”€ admin.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

# ğŸ“¦ **Installation & Setup**

### Prerequisites

- Python 3.8 or higher
- Redis server installed and running
- pip (Python package manager)

### 1ï¸âƒ£ Clone Repository

```bash
git clone <your-repo-url>
cd kipps_analysis
```

### 2ï¸âƒ£ Create Virtual Environment (Recommended)

```bash
python -m venv venv

# On Windows:
venv\Scripts\activate

# On Linux/Mac:
source venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Download NLTK Data

The analysis logic requires NLTK's WordNet corpus. Download it using:

```python
python -c "import nltk; nltk.download('wordnet')"
```

Alternatively, you can download it interactively:

```python
import nltk
nltk.download('wordnet')
```

### 5ï¸âƒ£ Run Database Migrations

```bash
python manage.py migrate
```

---

# ğŸ”„ **Background Services (Redis, Celery Worker & Celery Beat)**

For scheduled analysis, three services must run simultaneously:

### **1ï¸âƒ£ Redis Server (Message Broker)**

Used by Celery for sending tasks.

```bash
redis-server
```

ğŸ“¸ *Screenshot:*
![redis](screenshots/redis.png)

---

### **2ï¸âƒ£ Celery Worker (Executes Background Jobs)**

Processes analysis logic in the background.

```bash
celery -A kipps_analysis worker --pool=solo -l info
```

ğŸ“¸ *Screenshot:*
![worker](screenshots/celery_worker.png)

---

### **3ï¸âƒ£ Celery Beat (Task Scheduler)**

Triggers the `daily_analyse` task every day.

```bash
celery -A kipps_analysis beat -l info
```

ğŸ“¸ *Screenshot:*
![beat](screenshots/celery_beat.png)

---

# â–¶ï¸ **Run Django Server**

```bash
python manage.py runserver
```

---

# ğŸ“˜ **Swagger API Documentation**

Available at:

ğŸ‘‰ **[http://127.0.0.1:8000/swagger/](http://127.0.0.1:8000/swagger/)**

ğŸ“¸ *Screenshot:*
![swagger](screenshots/swagger.png)

---

# ğŸ“¡ **API Endpoints**

| Endpoint              | Method | Description                            |
| --------------------- | ------ | -------------------------------------- |
| `/api/conversations/` | POST   | Upload a conversation                  |
| `/api/analyse/<id>/`  | POST   | Analyse a specific conversation        |
| `/api/reports/`       | GET    | List all conversation analysis reports |

---

# ğŸ§ª **API Testing (Postman)**

### **1ï¸âƒ£ Upload Conversation**

![upload](screenshots/convo.png)

### **2ï¸âƒ£ Analyse Conversation**

![analyse](screenshots/analysis.png)

### **3ï¸âƒ£ View Reports**

![reports](screenshots/reports.png)

---

# ğŸ§  **Analysis Logic Explained**

### âœ” Clarity

Checks if AI responses are understandable, not too short or overly long.

### âœ” Relevance

Uses NLTK WordNet semantic similarity to match user intent with AI response.

### âœ” Accuracy

Decreases score if AI uses uncertain phrases like â€œmaybeâ€, â€œnot sureâ€.

### âœ” Completeness

Ensures every user message receives an AI reply.

### âœ” Sentiment

TextBlob polarity for user emotion detection.

### âœ” Empathy

Counts empathetic phrases like:
â€œSorryâ€, â€œI understandâ€, â€œI can helpâ€, â€œNo worriesâ€.

### âœ” Fallback Count

Detects fallback responses like:
â€œI donâ€™t knowâ€, â€œI cannot helpâ€.

### âœ” Resolution

Checks if conversation ended positively ("thanks", "solved", etc.).

### âœ” Response Time

Measures time gap between user â†’ AI messages.

### âœ” Overall Score

```
(clarity + relevance + accuracy + completeness + empathy) / 5
```

---

# â± **Daily Auto Analysis (Celery Beat)**

Every day, a scheduled task runs:

```python
@shared_task
def daily_analyse():
    conversations = Conversation.objects.filter(analysis__isnull=True)
    ...
```

Celery worker output example:

ğŸ“¸ *Screenshot:*
`![celery](screenshots/celery_success.png)`

---

# ğŸ§¾ **Example Analysis Output**

```json
{
    "clarity_score": 1.0,
    "relevance_score": 0.43,
    "accuracy_score": 1.0,
    "completeness_score": 1.0,
    "sentiment": "positive",
    "empathy_score": 0.5,
    "resolution": true,
    "fallback_count": 0,
    "escalation_needed": false,
    "average_response_time": 0.21,
    "overall_score": 0.78
}
```

---

# ğŸ **Conclusion**

This project successfully implements all required features of a complete **AI-based conversation analysis backend**, including:

* Conversation upload API
* Multi-metric conversation analysis
* Persistent storage of reports
* Automated daily background processing
* Redis + Celery Worker + Celery Beat integration
* Swagger API documentation
* Fully tested with Postman

The architecture follows clean backend development practices and can be easily extended with more advanced NLP models or additional scoring features in the future.

---